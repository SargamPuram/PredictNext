{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from the /data folder\n",
    "file_path = \"../data/OnlineRetail.csv\"  # Adjust path as needed\n",
    "data = pd.read_csv(file_path, on_bad_lines='skip', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded Successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029G</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029E</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InvoiceNo StockCode                          Description  Quantity  \\\n",
       "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
       "1    536365     71053                  WHITE METAL LANTERN         6   \n",
       "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
       "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
       "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
       "\n",
       "      InvoiceDate  UnitPrice  CustomerID         Country  \n",
       "0  12/1/2010 8:26       2.55     17850.0  United Kingdom  \n",
       "1  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
       "2  12/1/2010 8:26       2.75     17850.0  United Kingdom  \n",
       "3  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
       "4  12/1/2010 8:26       3.39     17850.0  United Kingdom  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the first few rows to check\n",
    "print(\"Dataset Loaded Successfully!\")\n",
    "display(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Remove rows with missing values in critical columns\n",
    "# Removing rows where 'InvoiceDate' and 'CustomerID' have missing values\n",
    "data = data.dropna(subset=['InvoiceDate', 'CustomerID'])\n",
    "\n",
    "# Step 2: Label encode the 'CustomerID' and 'Country' columns\n",
    "label_encoder = LabelEncoder()\n",
    "data['CustomerID'] = label_encoder.fit_transform(data['CustomerID'].astype(str))\n",
    "data['Country'] = label_encoder.fit_transform(data['Country'].astype(str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Scale numerical features\n",
    "numerical_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "scaler = StandardScaler()\n",
    "data[numerical_cols] = scaler.fit_transform(data[numerical_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Convert 'InvoiceDate' to datetime format\n",
    "data['InvoiceDate'] = pd.to_datetime(data['InvoiceDate'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Split the data into two transaction periods (6 months and next period)\n",
    "tx_6m = data[(data['InvoiceDate'] < pd.Timestamp('2011-09-01')) & \n",
    "             (data['InvoiceDate'] >= pd.Timestamp('2011-03-01'))].reset_index(drop=True)\n",
    "\n",
    "tx_next = data[(data['InvoiceDate'] >= pd.Timestamp('2011-09-01')) & \n",
    "               (data['InvoiceDate'] < pd.Timestamp('2011-12-01'))].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in tx_user after merge:\n",
      "CustomerID          0\n",
      "FirstPurchase    1113\n",
      "LastPurchase        0\n",
      "dtype: int64\n",
      "CustomerID       0\n",
      "FirstPurchase    0\n",
      "LastPurchase     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Create a user-level dataframe\n",
    "tx_user = pd.DataFrame(tx_6m['CustomerID'].unique(), columns=['CustomerID'])\n",
    "\n",
    "# Step 7: Get the last purchase for each customer in tx_6m\n",
    "last_purchase = tx_6m.groupby('CustomerID')['InvoiceDate'].max().reset_index()\n",
    "last_purchase.rename(columns={'InvoiceDate': 'LastPurchase'}, inplace=True)\n",
    "\n",
    "# Step 8: Get the first purchase for each customer in tx_next\n",
    "first_purchase = tx_next.groupby('CustomerID')['InvoiceDate'].min().reset_index()\n",
    "first_purchase.rename(columns={'InvoiceDate': 'FirstPurchase'}, inplace=True)\n",
    "\n",
    "# Step 9: Merge last and first purchases into tx_user\n",
    "tx_user = tx_user.merge(last_purchase, on='CustomerID', how='left')\n",
    "tx_user = tx_user.merge(first_purchase, on='CustomerID', how='left')\n",
    "\n",
    "# Check for missing values after merging first and last purchase\n",
    "print(\"Missing values in tx_user after merge:\")\n",
    "print(tx_user[['CustomerID', 'FirstPurchase', 'LastPurchase']].isnull().sum())\n",
    "\n",
    "# Fill missing 'FirstPurchase' with a valid date (e.g., '1900-01-01')\n",
    "tx_user['FirstPurchase'] = tx_user['FirstPurchase'].fillna(pd.Timestamp('1900-01-01'))  # Replace with a valid date\n",
    "print(tx_user[['CustomerID', 'FirstPurchase', 'LastPurchase']].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Calculate the Target (difference in days between first and last purchase)\n",
    "tx_user['Target'] = (tx_user['FirstPurchase'] - tx_user['LastPurchase']).dt.days\n",
    "\n",
    "# Step 11: Fill missing 'Target' values with 999\n",
    "tx_user['Target'] = tx_user['Target'].fillna(999).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerID          0\n",
      "LastPurchase        0\n",
      "FirstPurchase       0\n",
      "Target              0\n",
      "QuantitySum_x       0\n",
      "QuantityMean_x      0\n",
      "TotalSpendSum_x     0\n",
      "TotalSpendMean_x    0\n",
      "PurchaseCount_x     0\n",
      "Recency             0\n",
      "QuantitySum_y       0\n",
      "QuantityMean_y      0\n",
      "TotalSpendSum_y     0\n",
      "TotalSpendMean_y    0\n",
      "PurchaseCount_y     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 12: Feature Engineering: Aggregate features from tx_6m\n",
    "tx_6m['TotalSpend'] = tx_6m['Quantity'] * tx_6m['UnitPrice']\n",
    "\n",
    "user_features = tx_6m.groupby('CustomerID').agg({\n",
    "    'Quantity': ['sum', 'mean'],\n",
    "    'TotalSpend': ['sum', 'mean'],\n",
    "    'InvoiceDate': ['count']\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns for user features\n",
    "user_features.columns = ['CustomerID', 'QuantitySum', 'QuantityMean', 'TotalSpendSum', 'TotalSpendMean', 'PurchaseCount']\n",
    "\n",
    "# Rename the columns for better readability\n",
    "user_features.columns = ['CustomerID', 'QuantitySum', 'QuantityMean', 'TotalSpendSum', 'TotalSpendMean', 'PurchaseCount']\n",
    "\n",
    "# Step 2: Fill missing aggregated values with zero or NaN\n",
    "# If 'QuantitySum' has missing values, fill with 0 (or NaN, depending on what you want to do)\n",
    "user_features['QuantitySum'] = user_features['QuantitySum'].fillna(0)\n",
    "\n",
    "# Step 3: Merge user features with tx_user\n",
    "tx_user = tx_user.merge(user_features, on='CustomerID', how='left')\n",
    "\n",
    "# Step 4: Verify after merge to check for any remaining missing values\n",
    "print(tx_user.isnull().sum())\n",
    "\n",
    "# Step 13: Calculate Recency (days since last purchase)\n",
    "tx_user['Recency'] = (pd.Timestamp('2011-09-01') - tx_user['LastPurchase']).dt.days\n",
    "\n",
    "# Step 14: Create a new DataFrame for feature encoding (StockCode, etc.)\n",
    "tx_features = tx_6m[['CustomerID', 'InvoiceDate', 'Quantity', 'UnitPrice', 'StockCode']].copy()\n",
    "\n",
    "# Step 15: One-hot encode the 'StockCode' column\n",
    "tx_features = pd.get_dummies(tx_features, columns=['StockCode'], drop_first=True)\n",
    "\n",
    "# Step 16: Label encode 'CustomerID' in tx_features DataFrame\n",
    "tx_features['CustomerID'] = label_encoder.fit_transform(tx_features['CustomerID'].astype(str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerID                 float64\n",
      "LastPurchase        datetime64[ns]\n",
      "FirstPurchase       datetime64[ns]\n",
      "Target                       int64\n",
      "QuantitySum_x              float64\n",
      "QuantityMean_x             float64\n",
      "TotalSpendSum_x            float64\n",
      "TotalSpendMean_x           float64\n",
      "PurchaseCount_x              int64\n",
      "Recency                      int64\n",
      "QuantitySum_y              float64\n",
      "QuantityMean_y             float64\n",
      "TotalSpendSum_y            float64\n",
      "TotalSpendMean_y           float64\n",
      "PurchaseCount_y              int64\n",
      "dtype: object\n",
      "CustomerID        float64\n",
      "QuantitySum       float64\n",
      "QuantityMean      float64\n",
      "TotalSpendSum     float64\n",
      "TotalSpendMean    float64\n",
      "PurchaseCount       int64\n",
      "dtype: object\n",
      "CustomerID                  int64\n",
      "InvoiceDate        datetime64[ns]\n",
      "Quantity                  float64\n",
      "UnitPrice                 float64\n",
      "StockCode_10080              bool\n",
      "                        ...      \n",
      "StockCode_D                  bool\n",
      "StockCode_DOT                bool\n",
      "StockCode_M                  bool\n",
      "StockCode_PADS               bool\n",
      "StockCode_POST               bool\n",
      "Length: 3203, dtype: object\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "160083\n"
     ]
    }
   ],
   "source": [
    "# Step 17: Check data types, missing values, and duplicates in key columns\n",
    "print(tx_user.dtypes)\n",
    "print(user_features.dtypes)\n",
    "print(tx_features.dtypes)\n",
    "\n",
    "# Check for missing values\n",
    "print(tx_user['CustomerID'].isnull().sum())\n",
    "print(user_features['CustomerID'].isnull().sum())\n",
    "print(tx_features['CustomerID'].isnull().sum())\n",
    "\n",
    "# Check for duplicates in 'CustomerID'\n",
    "print(tx_user['CustomerID'].duplicated().sum())\n",
    "print(user_features['CustomerID'].duplicated().sum())\n",
    "print(tx_features['CustomerID'].duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_109744/311999628.py:13: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  final_features = tx_user.merge(user_features, on='CustomerID', how='left')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID        LastPurchase FirstPurchase  Target  QuantitySum_x  \\\n",
      "0           0 2011-05-19 14:14:00    1900-01-01  -40681      -0.699011   \n",
      "1           0 2011-05-19 14:14:00    1900-01-01  -40681      -0.699011   \n",
      "2           0 2011-05-19 14:14:00    1900-01-01  -40681      -0.699011   \n",
      "3           0 2011-05-19 14:14:00    1900-01-01  -40681      -0.699011   \n",
      "4           0 2011-05-19 14:14:00    1900-01-01  -40681      -0.699011   \n",
      "\n",
      "   QuantityMean_x  TotalSpendSum_x  TotalSpendMean_x  PurchaseCount_x  \\\n",
      "0         -0.0233         -0.00682         -0.000227               30   \n",
      "1         -0.0233         -0.00682         -0.000227               30   \n",
      "2         -0.0233         -0.00682         -0.000227               30   \n",
      "3         -0.0233         -0.00682         -0.000227               30   \n",
      "4         -0.0233         -0.00682         -0.000227               30   \n",
      "\n",
      "   Recency  ...  StockCode_90214V  StockCode_90214Y  StockCode_BANK CHARGES  \\\n",
      "0      104  ...             False             False                   False   \n",
      "1      104  ...             False             False                   False   \n",
      "2      104  ...             False             False                   False   \n",
      "3      104  ...             False             False                   False   \n",
      "4      104  ...             False             False                   False   \n",
      "\n",
      "   StockCode_C2  StockCode_CRUK  StockCode_D  StockCode_DOT  StockCode_M  \\\n",
      "0         False           False        False          False        False   \n",
      "1         False           False        False          False        False   \n",
      "2         False           False        False          False        False   \n",
      "3         False           False        False          False        False   \n",
      "4         False           False        False          False        False   \n",
      "\n",
      "   StockCode_PADS  StockCode_POST  \n",
      "0           False           False  \n",
      "1           False           False  \n",
      "2           False           False  \n",
      "3           False           False  \n",
      "4           False           False  \n",
      "\n",
      "[5 rows x 3222 columns]\n",
      "(131458, 3222)\n"
     ]
    }
   ],
   "source": [
    "# Step 18: Merge user features and transaction features\n",
    "\n",
    "# Convert CustomerID to int64 again to ensure there are no implicit floats\n",
    "tx_user['CustomerID'] = tx_user['CustomerID'].astype(int)\n",
    "tx_features['CustomerID'] = tx_features['CustomerID'].astype(int)\n",
    "\n",
    "# Drop rows with NaN in CustomerID if necessary\n",
    "tx_user = tx_user.dropna(subset=['CustomerID'])\n",
    "tx_features = tx_features.dropna(subset=['CustomerID'])\n",
    "\n",
    "# Step 1: Simplified merge for user features\n",
    "user_features = user_features[['CustomerID', 'QuantitySum', 'QuantityMean', 'TotalSpendSum', 'TotalSpendMean', 'PurchaseCount']]\n",
    "final_features = tx_user.merge(user_features, on='CustomerID', how='left')\n",
    "\n",
    "# Step 2: Simplified merge for transaction features (tx_features)\n",
    "final_features = final_features.merge(tx_features[['CustomerID'] + [col for col in tx_features.columns if col != 'CustomerID']], on='CustomerID', how='inner')\n",
    "\n",
    "# Step 3: Check the result of the merge\n",
    "print(final_features.head())\n",
    "print(final_features.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns: Index(['CustomerID', 'LastPurchase', 'FirstPurchase', 'Recency', 'QuantitySum',\n",
      "       'QuantityMean', 'TotalSpendSum', 'TotalSpendMean', 'PurchaseCount',\n",
      "       'InvoiceDate',\n",
      "       ...\n",
      "       'StockCode_90214V', 'StockCode_90214Y', 'StockCode_BANK CHARGES',\n",
      "       'StockCode_C2', 'StockCode_CRUK', 'StockCode_D', 'StockCode_DOT',\n",
      "       'StockCode_M', 'StockCode_PADS', 'StockCode_POST'],\n",
      "      dtype='object', length=3211)\n"
     ]
    }
   ],
   "source": [
    "# Step 19: Split data into features (X) and target (y)\n",
    "if 'Target' not in final_features.columns:\n",
    "    print(\"Target column is missing. Recheck the target calculation.\")\n",
    "else:\n",
    "    X = final_features.drop(columns=['Target'])  # Features\n",
    "    y = final_features['Target']  # Target (days until next purchase)\n",
    "    print(f\"Feature columns: {X.columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 20: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 105166 samples\n",
      "Testing set size: 26292 samples\n"
     ]
    }
   ],
   "source": [
    "# Print shapes of the resulting datasets\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerID             0\n",
      "LastPurchase           0\n",
      "FirstPurchase          0\n",
      "Recency                0\n",
      "QuantitySum       105166\n",
      "                   ...  \n",
      "StockCode_D            0\n",
      "StockCode_DOT          0\n",
      "StockCode_M            0\n",
      "StockCode_PADS         0\n",
      "StockCode_POST         0\n",
      "Length: 3211, dtype: int64\n",
      "CustomerID            0\n",
      "LastPurchase          0\n",
      "FirstPurchase         0\n",
      "Recency               0\n",
      "QuantitySum       26292\n",
      "                  ...  \n",
      "StockCode_D           0\n",
      "StockCode_DOT         0\n",
      "StockCode_M           0\n",
      "StockCode_PADS        0\n",
      "StockCode_POST        0\n",
      "Length: 3211, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the features after the split\n",
    "print(X_train.isnull().sum())  # Check missing values in training data\n",
    "print(X_test.isnull().sum())   # Check missing values in testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the datasets to a file\n",
    "with open('train_test_data.pkl', 'wb') as f:\n",
    "    pickle.dump((X_train, y_train, X_test, y_test), f)\n",
    "\n",
    "print(\"Data saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
